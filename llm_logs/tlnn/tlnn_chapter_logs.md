\# 协作日志：与 LLM 共创两层全连接网络



\*\*项目阶段\*\*：小作业 2 - 两层全连接网络 

\*\*协作伙伴\*\*：百度文心一言大模型



---



\## 第一部分：归一化技术深入理解



\### 探索点 1：BatchNorm 训练与推理模式差异



> \*\*我们提出的问题:\*\*  

> \&emsp;\&emsp;BatchNorm 在训练时使用的是当前批次的统计量，那 running mean/var 在训练中起什么作用？初始值为0/1会影响训练吗？



!\[与LLM的对话记录1](chat5.jpg)



\&emsp;\&emsp;通过对话，我们理解了 BatchNorm 的关键机制：\*\*训练时使用当前 batch 的统计量进行归一化，同时用指数滑动平均更新 running 统计量；推理时才固定使用 running 统计量\*\*。这解释了为什么初始值不影响训练效果，只影响推理的冷启动。



---



\## 第二部分：数据集划分与信息泄露



\### 探索点 2：验证集与测试集的正确使用



> \*\*我们提出的问题:\*\*  

> \&emsp;\&emsp;能把测试数据集当作验证数据集使用吗？



!\[与LLM的对话记录2](chat1.png)



\&emsp;\&emsp;LLM 明确指出了不建议这样做的原因：\*\*把测试集当验证集会让你对模型做选择与调参时"看见了测试集"，从而信息泄漏、性能高估\*\*，最终在真正未见数据上的泛化会变差。



\### 探索点 3：信息泄露的本质理解



> \*\*我们提出的问题:\*\*  

> \&emsp;\&emsp;但是在验证集上又不训练，是怎么泄露的呢？我现在最不明白的就是这个



!\[与LLM的对话记录3](chat2.png)



\&emsp;\&emsp;通过 LLM 的清晰解释，我们理解了信息泄露的本质：\*\*不是把验证集的样本喂给梯度，而是把验证集信息喂给了你的选择过程\*\*。当你尝试很多配置后，总会有某个配置碰巧在这份验证集上表现最好，即使它对真正的未见数据并不更好。



---



\## 第三部分：优化算法与归一化技术



\### 探索点 4：Adam 优化器与学习率调度的协同



> \*\*我们提出的问题:\*\*  

> \&emsp;\&emsp;Adam不是用了RMSprop的自适应调节学习率的大小吗，这样不够吗？



!\[与LLM的对话记录4](chat3.png)



\&emsp;\&emsp;我们理解了 Adam 和调度器的分工协作：\*\*Adam 提供参数维度的自适应缩放，调度器控制时间维度的全局策略\*\*。两者叠加使用能实现更稳定的训练（warmup）、更精细的收敛（衰减）和更好的泛化性能。



\### 探索点 5：各类归一化方法对比



> \*\*我们提出的问题:\*\*  

> \&emsp;\&emsp;不同的归一化方法到底在哪些轴上计算统计量？



!\[与LLM的对话记录5](chat4.png)



\&emsp;\&emsp;LLM 提供了清晰的速记表，帮助我们系统理解各归一化方法的差异：\*\*BatchNorm 在批次维度，LayerNorm 在特征维度，InstanceNorm 在空间维度\*\*。这为我们在不同场景下选择合适的归一化方法提供了理论指导。



---



\*\*总结\*\*：通过与 LLM 的深入对话，我们解决了实现过程中的关键技术难题，特别是对\*\*BatchNorm 工作机制、数据集划分原则、信息泄露机制、优化算法选择\*\*等核心概念建立了深刻理解。这些知识为我们构建稳健、可泛化的深度学习模型奠定了坚实基础。

